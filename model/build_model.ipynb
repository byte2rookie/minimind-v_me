{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "246ad362",
   "metadata": {},
   "source": [
    "# 搭建Minimind模型\n",
    "首先要理清模型结构<br>\n",
    "![structure](../images/LLM-structure.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1d3b34",
   "metadata": {},
   "source": [
    "# 搭建思路\n",
    "采用自底向上的方式搭建model，理清所有的因素\n",
    "- tokenizer\n",
    "- embedding\n",
    "- AttentionBlock\n",
    "- ffn\n",
    "- output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540ea420",
   "metadata": {},
   "source": [
    "# tokenizer\n",
    "在此之前已经训练好了tokenizer了，这里我们就开始利用之前训练好的tokenizer，来将原始信息转为input_ids的结构<br>\n",
    "这里学习到的点：padding来统一输出input_ids的形状。left-padding和right-padding也是常见考察点<br>\n",
    "注意！tokenizer初始化的时候就定好了padding的方向了，后续无法更改的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46da48af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/zyp/miniconda3/envs/minimind/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs_r.shape= torch.Size([2, 100])\n",
      "inputs_r tensor([[   1,   87,   93,  307,   73,   81,  203,  397,  924, 5235, 3317, 2117,\n",
      "          265, 2603, 1132, 2599,  703,  472,  997,    2,  203,    1,   89,   87,\n",
      "         3709,  203,  397, 2722, 3016,  425,    2,  203,    1,   69,   87,   87,\n",
      "           77,  307, 3924,   88,  203,  301, 2722, 1284,    2,  203,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   1,   87,   93,  307,   73,   81,  203,  397,  924, 5990, 2391,  328,\n",
      "          240,  101, 3789, 2117,  265, 2603, 1132, 1395,  264,  703,  472,  997,\n",
      "            2,  203,    1,   89,   87, 3709,  203,  397, 2722, 3016,  425,    2,\n",
      "          203,    1,   69,   87,   87,   77,  307, 3924,   88,  203,  301, 2722,\n",
      "         4863,    2,  203,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0]])\n",
      "inputs_l.shape= torch.Size([2, 100])\n",
      "inputs_l tensor([[   1,   87,   93,  307,   73,   81,  203,  397,  924, 5235, 3317, 2117,\n",
      "          265, 2603, 1132, 2599,  703,  472,  997,    2,  203,    1,   89,   87,\n",
      "         3709,  203,  397, 2722, 3016,  425,    2,  203,    1,   69,   87,   87,\n",
      "           77,  307, 3924,   88,  203,  301, 2722, 1284,    2,  203,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   1,   87,   93,  307,   73,   81,  203,  397,  924, 5990, 2391,  328,\n",
      "          240,  101, 3789, 2117,  265, 2603, 1132, 1395,  264,  703,  472,  997,\n",
      "            2,  203,    1,   89,   87, 3709,  203,  397, 2722, 3016,  425,    2,\n",
      "          203,    1,   69,   87,   87,   77,  307, 3924,   88,  203,  301, 2722,\n",
      "         4863,    2,  203,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0]])\n",
      "torch.Size([2, 100])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "from numpy import pad\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer_path=\"./\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path,padding_side=\"right\") # padding_side可以是\"left\"或\"right\"，默认是\"right\"\n",
    "#单条信息的情况,batch=1\n",
    "messages = [[\n",
    "        {\"role\": \"system\", \"content\": \"你是一个优秀的聊天机器人，总是给我正确的回应！\"},\n",
    "        {\"role\": \"user\", \"content\": '你来自哪里？'},\n",
    "        {\"role\": \"assistant\", \"content\": '我来自地球'}\n",
    "    ],[\n",
    "        {\"role\": \"system\", \"content\": \"你是一个糟糕的捣乱机器人，总是给我错误的回应！\"},\n",
    "        {\"role\": \"user\", \"content\": '你来自哪里？'},\n",
    "        {\"role\": \"assistant\", \"content\": '我来自火星'}\n",
    "    ],\n",
    "    ]\n",
    "#多条信息\n",
    "\n",
    "inputs_r = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True,return_tensors=\"pt\",padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=100,\n",
    "    padding_side=\"right\"# 可以尝试\"left\"或\"right\"\n",
    "    ) #直接使用会导致长度不一致的典型问题，因此需要padding到一致长度\n",
    "print(\"inputs_r.shape=\",inputs_r.shape)\n",
    "print(\"inputs_r\",inputs_r)\n",
    "inputs_l = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True,return_tensors=\"pt\",padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=100,\n",
    "    padding_side=\"left\"# 可以尝试\"left\"或\"right\"\n",
    "    )\n",
    "print(\"inputs_l.shape=\",inputs_l.shape)\n",
    "print(\"inputs_l\",inputs_l)\n",
    "\n",
    "#由于一开始tokenizer初始化的时候就定好了padding的方向了，所以后续无法更改的。上面也对比出来了\n",
    "\n",
    "input_ids=inputs_r\n",
    "print(input_ids.shape)\n",
    "print(type(input_ids))\n",
    "# 可知有很多tokenizer输出的tensor形状了\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8429e4c6",
   "metadata": {},
   "source": [
    "# embedding\n",
    "tokenizer实现了word2vec，而下一步就是将原始的类似one-hot编码转化为向量化的压缩的input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fee0d5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res.shape= torch.Size([2, 100, 128])\n",
      "res tensor([[[ 0.6838, -0.2991,  0.8177,  ...,  0.8232,  1.6614,  2.9230],\n",
      "         [ 0.1591, -0.4361, -0.7887,  ...,  0.1875, -0.6190,  1.5368],\n",
      "         [ 0.7740, -0.9560,  0.1643,  ...,  0.1395,  0.2955, -0.0335],\n",
      "         ...,\n",
      "         [ 0.8112, -0.2788,  1.8459,  ...,  0.3327,  0.3586,  1.2822],\n",
      "         [ 0.8112, -0.2788,  1.8459,  ...,  0.3327,  0.3586,  1.2822],\n",
      "         [ 0.8112, -0.2788,  1.8459,  ...,  0.3327,  0.3586,  1.2822]],\n",
      "\n",
      "        [[ 0.6838, -0.2991,  0.8177,  ...,  0.8232,  1.6614,  2.9230],\n",
      "         [ 0.1591, -0.4361, -0.7887,  ...,  0.1875, -0.6190,  1.5368],\n",
      "         [ 0.7740, -0.9560,  0.1643,  ...,  0.1395,  0.2955, -0.0335],\n",
      "         ...,\n",
      "         [ 0.8112, -0.2788,  1.8459,  ...,  0.3327,  0.3586,  1.2822],\n",
      "         [ 0.8112, -0.2788,  1.8459,  ...,  0.3327,  0.3586,  1.2822],\n",
      "         [ 0.8112, -0.2788,  1.8459,  ...,  0.3327,  0.3586,  1.2822]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#实现embedding\n",
    "import torch\n",
    "from torch import nn\n",
    "# embedding\n",
    "class Embedding(nn.Module):\n",
    "    def __init__(self,vocab_size,embed_dim):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "    def forward(self,input_ids):\n",
    "        return self.embedding(input_ids)\n",
    "\n",
    "# 测试embedding\n",
    "vocab_size = tokenizer.vocab_size\n",
    "embed_dim = 128  # 嵌入维度\n",
    "embedding_layer = Embedding(vocab_size, embed_dim)\n",
    "# input_ids是tokenizer输出的input_ids\n",
    "res= embedding_layer(input_ids)\n",
    "print(\"res.shape=\",res.shape)\n",
    "print(\"res\",res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c173daa5",
   "metadata": {},
   "source": [
    "# AttentionBlock\n",
    "主要分为三个组件\n",
    "- RMSNorm\n",
    "- GQA\n",
    "- FFN\n",
    "embedding结束后，输入向量压缩为了[2,100,128]的tensor<br>\n",
    "将这个tensor输入attentionblock，捕捉tensor内部的注意力关系<br>\n",
    "这里采用的GQA机制，需要实现GQA，还需要实现RoPE编码，从而捕捉tensor内部的位置和时序关系\n",
    "![img](../images/LLM-structure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5ffedc",
   "metadata": {},
   "source": [
    "## RMSNorm\n",
    "### 均方根层归一化 (Root Mean Square Layer Normalization, RMSNorm)\n",
    "\n",
    "RMSNorm 是对 LayerNorm 的一个改进,  没有做 re-center 操作（移除了均值项）, 可以看作 LayerNorm 在均值为零时的特例, 使用平方根均值归一化降低噪声影响。\n",
    "\n",
    "- **Layer Norm**\n",
    "\n",
    "$$y = \\frac{x-E(x)}{\\sqrt{Var(x) + \\epsilon}} * \\gamma + \\beta$$\n",
    "\n",
    "假设输入张量形状为 (batch_size,  sequence_length,  embedding_dim), 层归一化对 embedding_dim 维度进行归一化操作, 其中,  $\\epsilon$ 是一个超参数, 用于防止分母为零导致结果上溢,  $\\gamma$,  $\\beta$ 均为可学习参数。\n",
    "\n",
    "- **RMS Norm**\n",
    "\n",
    "$$a_i=\\frac{a_i}{RMS(a) + \\epsilon} * \\gamma,  \\quad where \\quad RMS(a) = \\sqrt{\\frac{1}{n}\\sum^n_{i=1}a^2_i}.$$\n",
    "\n",
    "假设输入张量形状为 (batch_size,  sequence_length,  embedding_dim), RMS Norm 对 embedding_dim 维度进行归一化,其中,  其中,  $\\epsilon$ 是一个超参数, 用于防止分母为零导致结果上溢, $\\gamma$ 为可学习参数.\n",
    "\n",
    "不难发现, 当均值为零时, Layer Norm 退化为 RMS Norm. 这是因为 RMS Norm 在 Layer Norm 的基础上舍弃了中心化操作, 仅用缩放进行归一化, 其不改变数据原本的分布, 有利于激活函数输出的稳定."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99585b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_tensor tensor([[[ 0.0882,  2.0853, -1.8059,  ..., -1.1505,  0.4109, -0.6234],\n",
      "         [-0.2026,  0.2099,  0.6908,  ..., -0.3157, -1.7592, -0.2903],\n",
      "         [-1.9698, -0.1924,  0.6977,  ..., -0.2409, -0.1523,  1.0376],\n",
      "         ...,\n",
      "         [ 0.4626, -0.1045,  1.1635,  ..., -0.3794, -1.5879, -2.1123],\n",
      "         [-0.4531, -0.0845,  2.0073,  ..., -0.2041,  1.1379,  0.2551],\n",
      "         [ 0.8110,  1.2606, -1.3102,  ..., -1.4146, -0.1723, -0.7322]],\n",
      "\n",
      "        [[-0.2703, -0.2388,  0.5468,  ...,  2.2620,  1.3278, -0.0072],\n",
      "         [-1.7425,  0.1245, -0.6601,  ..., -0.7695,  0.3383, -0.4106],\n",
      "         [ 1.7596, -2.1032, -0.0324,  ..., -0.0683, -0.0102, -2.2862],\n",
      "         ...,\n",
      "         [-0.6159, -0.4573,  0.8271,  ..., -0.7213, -1.7506,  1.1421],\n",
      "         [ 0.9572, -0.1877, -1.8484,  ..., -1.0934, -0.7228,  0.2555],\n",
      "         [ 1.2894,  0.7856, -2.4600,  ..., -0.0700,  0.0387, -0.8012]]])\n",
      "output_tensor tensor([[[ 0.0804,  1.9000, -1.6454,  ..., -1.0482,  0.3744, -0.5680],\n",
      "         [-0.1931,  0.2001,  0.6585,  ..., -0.3010, -1.6771, -0.2768],\n",
      "         [-1.9303, -0.1885,  0.6837,  ..., -0.2361, -0.1492,  1.0168],\n",
      "         ...,\n",
      "         [ 0.4597, -0.1038,  1.1560,  ..., -0.3769, -1.5777, -2.0987],\n",
      "         [-0.5358, -0.0999,  2.3737,  ..., -0.2414,  1.3455,  0.3016],\n",
      "         [ 0.8241,  1.2810, -1.3314,  ..., -1.4375, -0.1751, -0.7440]],\n",
      "\n",
      "        [[-0.2382, -0.2104,  0.4818,  ...,  1.9932,  1.1700, -0.0063],\n",
      "         [-1.7673,  0.1263, -0.6694,  ..., -0.7805,  0.3431, -0.4164],\n",
      "         [ 1.5984, -1.9106, -0.0295,  ..., -0.0620, -0.0093, -2.0768],\n",
      "         ...,\n",
      "         [-0.6182, -0.4589,  0.8301,  ..., -0.7240, -1.7570,  1.1462],\n",
      "         [ 0.8514, -0.1670, -1.6442,  ..., -0.9726, -0.6430,  0.2273],\n",
      "         [ 1.2626,  0.7693, -2.4089,  ..., -0.0686,  0.0379, -0.7845]]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self,embed_dim,eps=1e-6):\n",
    "        super(RMSNorm,self).__init__()\n",
    "        self.embed_dim=embed_dim\n",
    "        self.eps=eps\n",
    "        self.weight=nn.Parameter(torch.ones(embed_dim))\n",
    "    def forward(self,x):\n",
    "        return x*torch.rsqrt(x.pow(2).mean(-1,keepdim=True)+self.eps).type_as(x)*self.weight\n",
    "# 测试RMSNorm\n",
    "embed_dim = 128  # 嵌入维度\n",
    "rmsnorm_layer = RMSNorm(embed_dim)\n",
    "input_tensor = torch.randn(2, 100, embed_dim)  # 假设输入的tensor形状为[batch_size, seq_length, embed_dim]\n",
    "output_tensor = rmsnorm_layer(input_tensor)\n",
    "print(\"input_tensor\",input_tensor)\n",
    "print(\"output_tensor\",output_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bf6984",
   "metadata": {},
   "source": [
    "## RoPE\n",
    "### Rotary Position Embedding, RoPE\n",
    "\n",
    "旋转位置编码是一种能将相对位置信息集成到 self-attention 中, 进而提升 transformer 架构性能的位置编码方式, 和绝对位置编码相比, RoPE 具有很好的外推性, 是目前的主流位置编码方式.\n",
    "\n",
    "外推性的解释, 通俗来说就是训练的时候限制了 512 的上下文长度，那么推理时如果面对超过该长度的文本，LLM 可能无法正确处理.\n",
    "\n",
    "- **绝对位置编码**\n",
    "\n",
    "绝对位置编码是早期 Transformer 架构采用的绝对位置编码方案，及那个每个位置映射为固定的向量表示.\n",
    "\n",
    "$$f_{t:t\\in\\{q,k,v\\}}(\\boldsymbol{x}_i,i)=\\boldsymbol{W}_{t:t\\in\\{q,k,v\\}}(\\boldsymbol{x}_i+\\boldsymbol{p}_i)$$\n",
    "\n",
    "其中编码向量 $p_i$ 的计算使用如下公式：\n",
    "\n",
    "$$\\boldsymbol{p}_{i,2t}=\\sin\\left(k/1000^{2t/d}\\right), \\boldsymbol{p}_{i,2t+1}=\\cos\\left(k/1000^{2t/d}\\right)$$\n",
    "\n",
    "正如其名，绝对位置编码只考虑了输入序列中的绝对位置关系，对于 token 之间的相对信息则没有纳入考虑.\n",
    "\n",
    "- **旋转位置编码**\n",
    "\n",
    "假定 query 和 key 的内积操作可以被函数 g 表示，该函数 g 的输入是词嵌入向量 $x_m, x_n$ 和它们之间的相对位置 $m-n$:\n",
    "\n",
    "$$<f_q(x_m ,m), f_k(x_n, n)>=g(x_m, x_n, m, n)$$\n",
    "\n",
    "旋转位置编码就是找到一个使上式成立的位置编码方式. \n",
    "\n",
    "出于认识的目的，我们省略复杂的数学推导，直接看 RoPE 的的结论：\n",
    "\n",
    "存在这样一个正交矩阵：\n",
    "\n",
    "$$\\boldsymbol{R}_{\\Theta,m}^d=\\underbrace{\\begin{pmatrix}\\cos m\\theta_0&-\\sin m\\theta_0&0&0&\\cdots&0&0\\\\\\sin m\\theta_0&\\cos m\\theta_0&0&0&\\cdots&0&0\\\\0&0&\\cos m\\theta_1&-\\sin m\\theta_1&\\cdots&0&0\\\\0&0&\\sin m\\theta_1&\\cos m\\theta_1&\\cdots&0&0\\\\\\vdots&\\vdots&\\vdots&\\vdots&\\ddots&\\vdots&\\vdots\\\\0&0&0&0&\\cdots&\\cos m\\theta_{d/2-1}&-\\sin m\\theta_{d/2-1}&-\\sin m\\theta_{d/2-1}\\end{pmatrix}}_{\\boldsymbol{W}_m}$$\n",
    "\n",
    "其中，$\\Theta=\\left\\{\\theta_i=10000^{-2(i-1)/d},i\\in[1,2,\\ldots,d/2]\\right\\}$\n",
    "\n",
    "我们可以将 query 和 key 的内积操作转换为与原始向量 $x$ 相关的以下等价形式：\n",
    "\n",
    "$$\n",
    "\\boldsymbol{q}_m^\\mathbf{T}\\boldsymbol{k}_n=\\left(\\boldsymbol{R}_{\\Theta,m}^d\\boldsymbol{W}_q\\boldsymbol{x}_m\\right)^\\mathbf{T}\\left(\\boldsymbol{R}_{\\Theta,n}^d\\boldsymbol{W}_k\\boldsymbol{x}_n\\right)=\\boldsymbol{x}_m^\\mathbf{T}\\boldsymbol{W}_q\\boldsymbol{R}_{\\Theta,n-m}^d\\boldsymbol{W}_k\\boldsymbol{x}_n\n",
    "$$\n",
    "\n",
    "其中， $\\boldsymbol{R}_{\\Theta,n-m}^d=\\left(\\boldsymbol{R}_{\\Theta,m}^d\\right)^\\mathbf{T}\\boldsymbol{R}_{\\Theta,n}^d$.\n",
    "\n",
    "由于 $\\boldsymbol{R}_{\\Theta,m}^d$ 的稀疏性，直接使用矩阵乘法会浪费算力，因此代码中采用下述方式实现：\n",
    "\n",
    "$$\\boldsymbol{R}_{\\Theta,m}^{d}\\boldsymbol{x}=\\begin{pmatrix}x_{0}\\\\x_{1}\\\\x_{2}\\\\x_{3}\\\\\\vdots\\\\x_{d-2}\\\\x_{d-1}\\end{pmatrix}\\otimes\\begin{pmatrix}\\cos m\\theta_{0}\\\\\\cos m\\theta_{0}\\\\\\cos m\\theta_{1}\\\\\\cos m\\theta_{1}\\\\\\vdots\\\\\\cos m\\theta_{d/2-1}\\\\\\cos m\\theta_{d/2-1}\\end{pmatrix}+\\begin{pmatrix}-x_{1}\\\\x_{0}\\\\-x_{3}\\\\x_{2}\\\\\\vdots\\\\-x_{d-1}\\\\x_{d-2}\\end{pmatrix}\\otimes\\begin{pmatrix}\\sin m\\theta_{0}\\\\\\sin m\\theta_{0}\\\\\\sin m\\theta_{1}\\\\\\sin m\\theta_{1}\\\\\\vdots\\\\\\sin m\\theta_{d/2-1}\\\\\\sin m\\theta_{d/2-1}\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c1a7fc",
   "metadata": {},
   "source": [
    "简而言之，RoPE就是用绝对编码的形式，表示出相对编码的关系，这样同时具有了绝对编码的简洁和相对编码的位置信息泛化性<br>\n",
    "此处的ROPE的实现主要参考的是LLama的RoPE实现\n",
    "[LLAMA实现](https://blog.csdn.net/m0_55846238/article/details/145728695)<br>\n",
    "对旋转编码理解困难，可以参考[无痛理解RoPE](https://zhuanlan.zhihu.com/p/8306958113)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157c23d2",
   "metadata": {},
   "source": [
    "大概归纳一下，旋转编码主要两步，首先是制作 $m\\Theta$ 的旋转角度的表，之后再应用这个表，用于编码qk\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bfc96f",
   "metadata": {},
   "source": [
    "### 首先制作$m\\Theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a81b9293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freqs.shape= torch.Size([64])\n",
      "m.shape= torch.Size([100])\n",
      "freqs.shape= torch.Size([100, 64])\n",
      "pos_cis.shape= torch.Size([100, 64])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "def precompute_pos_cis(dim,seqlen,theta=1e5):\n",
    "    #这里//2是因为要把dim分成两半，前半部分用于cos，后半部分用于sin，所以只会用到一个theta\n",
    "    freqs=1.0/(theta**(torch.arange(0,dim,2)[:dim//2].float()/dim))\n",
    "    print(\"freqs.shape=\",freqs.shape)\n",
    "    \n",
    "    m=torch.arange(seqlen,device=freqs.device)\n",
    "    print(\"m.shape=\",m.shape)\n",
    "\n",
    "    freqs=torch.outer(m,freqs).float()\n",
    "    print(\"freqs.shape=\",freqs.shape)\n",
    "\n",
    "    pos_cis=torch.polar(torch.ones_like(freqs),freqs)\n",
    "    print(\"pos_cis.shape=\",pos_cis.shape)\n",
    "    return pos_cis\n",
    "\n",
    "# 测试precompute_pos_cis\n",
    "dim = 128  # 嵌入维度\n",
    "seqlen = 100  # 序列长度\n",
    "pos_cis = precompute_pos_cis(dim, seqlen)\n",
    "print(type(pos_cis))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dc3bd1",
   "metadata": {},
   "source": [
    "### 然后将$m\\Theta$应用到旋转编码计算中去"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a6d928d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freqs.shape= torch.Size([4])\n",
      "m.shape= torch.Size([3])\n",
      "freqs.shape= torch.Size([3, 4])\n",
      "pos_cis.shape= torch.Size([3, 4])\n",
      "<class 'torch.Tensor'>\n",
      "xq_.shape= torch.Size([2, 3, 2, 4])\n",
      "pos_cis shape: torch.Size([1, 3, 1, 4])\n",
      "xq_ shape: torch.Size([2, 3, 2, 4])\n",
      "xk_ shape: torch.Size([2, 3, 2, 4])\n",
      "xq shape: torch.Size([2, 3, 2, 8])\n",
      "xk shape: torch.Size([2, 3, 2, 8])\n",
      "xq_out_shape: torch.Size([2, 3, 2, 8])\n",
      "xk_out_shape: torch.Size([2, 3, 2, 8])\n",
      "pos_cis: tensor([[ 1.0000+0.0000e+00j,  1.0000+0.0000e+00j,  1.0000+0.0000e+00j,\n",
      "          1.0000+0.0000e+00j],\n",
      "        [ 0.5403+8.4147e-01j,  0.9984+5.6204e-02j,  1.0000+3.1623e-03j,\n",
      "          1.0000+1.7783e-04j],\n",
      "        [-0.4161+9.0930e-01j,  0.9937+1.1223e-01j,  1.0000+6.3245e-03j,\n",
      "          1.0000+3.5566e-04j]])\n",
      "pos_cis shape: torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "def apply_rotary_emb(xq,xk,pos_cis):\n",
    "    xq_=torch.view_as_complex(xq.float().reshape(*xq.shape[:-1],-1,2))\n",
    "    xk_=torch.view_as_complex(xk.float().reshape(*xk.shape[:-1],-1,2))\n",
    "    #由于view_as_complex,最后一维合并了，就变成了dim//2的形状\n",
    "    print(\"xq_.shape=\",xq_.shape)\n",
    "    def unite_shape(pos_cis,x):\n",
    "        #将pos_cis对齐x的形状\n",
    "        ndim = x.ndim\n",
    "        assert 0 <= 1 < ndim\n",
    "        #x形状一般为(batch_size, seq_len, n_heads, head_dim//2)\n",
    "        #这里确保freqs_cis与x的seq_len, head_dim//2维度一致, RoPE是对每个头分别进行的\n",
    "        assert pos_cis.shape == (x.shape[1],  x.shape[-1]),f\"pos_cis.shape:({pos_cis.shape}),(x.shape[1],  x.shape[-1])={(x.shape[1],  x.shape[-1])}\"\n",
    "        shape = [d if i == 1 or i == ndim - 1 else 1 for i,  d in enumerate(x.shape)]\n",
    "        return pos_cis.view(*shape)\n",
    "    pos_cis = unite_shape(pos_cis, xq_)\n",
    "    #将pos_cis应用到xq_和xk_上(和输入对齐)\n",
    "    print(\"pos_cis shape:\", pos_cis.shape)\n",
    "    print(\"xq_ shape:\", xq_.shape)\n",
    "    print(\"xk_ shape:\", xk_.shape)\n",
    "    xq_out=torch.view_as_real(xq_ * pos_cis).flatten(3)\n",
    "    xk_out=torch.view_as_real(xk_ * pos_cis).flatten(3)\n",
    "    return xq_out, xk_out\n",
    "#测试一下apply_rotary_emb函数\n",
    "xq = torch.randn(2, 3, 2,8)  # (bs, seqlen, dim)\n",
    "xk = torch.randn(2, 3, 2,8)  # (bs, seqlen, dim)\n",
    "pos_cis = precompute_pos_cis(dim=8, seqlen=3, theta=1e5)\n",
    "print(type(pos_cis))\n",
    "xq_out, xk_out = apply_rotary_emb(xq, xk, pos_cis)\n",
    "print(\"xq shape:\", xq.shape)  # 应该是 (bs, seqlen, dim)\n",
    "print(\"xk shape:\", xk.shape)  # 应该是 (bs, seqlen, dim)\n",
    "\n",
    "print(\"xq_out_shape:\", xq_out.shape)  # 应该是 (bs, seqlen, dim\n",
    "print(\"xk_out_shape:\", xk_out.shape)  # 应该是 (bs, seqlen, dim\n",
    "# print(\"xq_out:\", xq_out)\n",
    "# print(\"xk_out:\", xk_out)\n",
    "print(\"pos_cis:\", pos_cis)\n",
    "print(\"pos_cis shape:\", pos_cis.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4ae339",
   "metadata": {},
   "source": [
    "# GQA\n",
    "![img](../images/LLM-structure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21547fd3",
   "metadata": {},
   "source": [
    "### 对齐q与kv的工具函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c0284e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[[[-0.6247,  0.7589, -0.7877,  0.3288, -1.5248, -0.6347,  0.8084,\n",
      "            0.2233],\n",
      "          [ 0.8526,  0.6423, -0.5520, -1.8552,  0.8973, -1.5722, -0.5682,\n",
      "            0.0765],\n",
      "          [-0.8539, -0.2294,  0.8187, -0.8471, -0.4265,  2.6147, -1.3418,\n",
      "           -0.4685],\n",
      "          [ 0.2785, -1.2338,  1.9119, -0.2724, -0.8014, -0.2021, -0.0670,\n",
      "            0.8867]],\n",
      "\n",
      "         [[ 1.1346,  0.4250, -0.3245, -1.0280, -0.4393,  2.6461,  0.2373,\n",
      "           -0.1676],\n",
      "          [ 0.7621,  0.3029, -1.9954,  2.1155, -0.8595, -1.0120, -0.7186,\n",
      "            0.5218],\n",
      "          [-1.3487, -1.7394, -0.1029, -0.4240, -1.2830,  0.2299,  0.7985,\n",
      "            2.4696],\n",
      "          [-0.2083,  0.4519,  0.3335,  1.1183, -0.0557,  1.3877, -0.9095,\n",
      "           -0.5147]],\n",
      "\n",
      "         [[ 1.2585,  0.2331, -0.0595, -0.9119,  1.2068, -1.7038,  0.0242,\n",
      "           -0.0851],\n",
      "          [ 0.0468, -0.2321, -3.1558, -0.3373,  0.7312, -0.3929, -0.3298,\n",
      "           -0.6969],\n",
      "          [-0.2102, -0.2781,  0.6874,  0.7383,  0.5918, -1.0455, -1.6094,\n",
      "            2.6959],\n",
      "          [-2.3652,  2.2381, -0.0986, -0.9634,  0.7393,  0.6570, -0.0265,\n",
      "            1.6448]]],\n",
      "\n",
      "\n",
      "        [[[-0.4871,  0.7296, -1.5554, -1.0390, -0.0105, -0.4779,  1.0036,\n",
      "            0.1428],\n",
      "          [ 1.4623,  0.5581,  0.7878, -0.3435, -1.3308,  0.4386, -0.1078,\n",
      "           -0.2736],\n",
      "          [ 1.7259, -0.4413, -0.1517,  0.2755, -0.8722, -0.7529, -1.5641,\n",
      "           -0.9575],\n",
      "          [-0.2509,  0.0434,  0.3033,  2.6338, -0.1515,  0.2691, -1.1761,\n",
      "            0.0842]],\n",
      "\n",
      "         [[ 0.4085, -0.1409,  1.7158,  0.8018, -0.4079,  0.7252, -0.2419,\n",
      "            0.7418],\n",
      "          [ 1.1222, -1.3883,  1.2917, -0.4612, -1.9804, -1.1041, -0.1382,\n",
      "            0.1671],\n",
      "          [ 0.6102,  1.5597, -2.1604,  1.6891,  0.7275,  0.6308, -0.4403,\n",
      "            0.7499],\n",
      "          [ 0.8432,  1.8173, -1.1394,  1.1597,  0.3569, -2.2435,  0.6788,\n",
      "            0.8430]],\n",
      "\n",
      "         [[-2.6243,  0.0688,  0.3284,  0.0297,  0.3668, -2.2625,  0.2016,\n",
      "            1.2607],\n",
      "          [ 0.0681,  0.6417,  0.2731,  0.1266, -0.4223,  0.4485, -0.7358,\n",
      "           -0.2751],\n",
      "          [-1.0429,  1.6223, -0.9959, -1.1272,  0.9117, -0.0953,  1.2329,\n",
      "            0.3859],\n",
      "          [ 0.7555,  0.9651, -0.3692, -2.5143,  0.3978, -1.1836, -1.2457,\n",
      "           -0.2673]]]])\n",
      "x_repeated: tensor([[[[-0.6247,  0.7589, -0.7877,  0.3288, -1.5248, -0.6347,  0.8084,\n",
      "            0.2233],\n",
      "          [-0.6247,  0.7589, -0.7877,  0.3288, -1.5248, -0.6347,  0.8084,\n",
      "            0.2233],\n",
      "          [ 0.8526,  0.6423, -0.5520, -1.8552,  0.8973, -1.5722, -0.5682,\n",
      "            0.0765],\n",
      "          [ 0.8526,  0.6423, -0.5520, -1.8552,  0.8973, -1.5722, -0.5682,\n",
      "            0.0765],\n",
      "          [-0.8539, -0.2294,  0.8187, -0.8471, -0.4265,  2.6147, -1.3418,\n",
      "           -0.4685],\n",
      "          [-0.8539, -0.2294,  0.8187, -0.8471, -0.4265,  2.6147, -1.3418,\n",
      "           -0.4685],\n",
      "          [ 0.2785, -1.2338,  1.9119, -0.2724, -0.8014, -0.2021, -0.0670,\n",
      "            0.8867],\n",
      "          [ 0.2785, -1.2338,  1.9119, -0.2724, -0.8014, -0.2021, -0.0670,\n",
      "            0.8867]],\n",
      "\n",
      "         [[ 1.1346,  0.4250, -0.3245, -1.0280, -0.4393,  2.6461,  0.2373,\n",
      "           -0.1676],\n",
      "          [ 1.1346,  0.4250, -0.3245, -1.0280, -0.4393,  2.6461,  0.2373,\n",
      "           -0.1676],\n",
      "          [ 0.7621,  0.3029, -1.9954,  2.1155, -0.8595, -1.0120, -0.7186,\n",
      "            0.5218],\n",
      "          [ 0.7621,  0.3029, -1.9954,  2.1155, -0.8595, -1.0120, -0.7186,\n",
      "            0.5218],\n",
      "          [-1.3487, -1.7394, -0.1029, -0.4240, -1.2830,  0.2299,  0.7985,\n",
      "            2.4696],\n",
      "          [-1.3487, -1.7394, -0.1029, -0.4240, -1.2830,  0.2299,  0.7985,\n",
      "            2.4696],\n",
      "          [-0.2083,  0.4519,  0.3335,  1.1183, -0.0557,  1.3877, -0.9095,\n",
      "           -0.5147],\n",
      "          [-0.2083,  0.4519,  0.3335,  1.1183, -0.0557,  1.3877, -0.9095,\n",
      "           -0.5147]],\n",
      "\n",
      "         [[ 1.2585,  0.2331, -0.0595, -0.9119,  1.2068, -1.7038,  0.0242,\n",
      "           -0.0851],\n",
      "          [ 1.2585,  0.2331, -0.0595, -0.9119,  1.2068, -1.7038,  0.0242,\n",
      "           -0.0851],\n",
      "          [ 0.0468, -0.2321, -3.1558, -0.3373,  0.7312, -0.3929, -0.3298,\n",
      "           -0.6969],\n",
      "          [ 0.0468, -0.2321, -3.1558, -0.3373,  0.7312, -0.3929, -0.3298,\n",
      "           -0.6969],\n",
      "          [-0.2102, -0.2781,  0.6874,  0.7383,  0.5918, -1.0455, -1.6094,\n",
      "            2.6959],\n",
      "          [-0.2102, -0.2781,  0.6874,  0.7383,  0.5918, -1.0455, -1.6094,\n",
      "            2.6959],\n",
      "          [-2.3652,  2.2381, -0.0986, -0.9634,  0.7393,  0.6570, -0.0265,\n",
      "            1.6448],\n",
      "          [-2.3652,  2.2381, -0.0986, -0.9634,  0.7393,  0.6570, -0.0265,\n",
      "            1.6448]]],\n",
      "\n",
      "\n",
      "        [[[-0.4871,  0.7296, -1.5554, -1.0390, -0.0105, -0.4779,  1.0036,\n",
      "            0.1428],\n",
      "          [-0.4871,  0.7296, -1.5554, -1.0390, -0.0105, -0.4779,  1.0036,\n",
      "            0.1428],\n",
      "          [ 1.4623,  0.5581,  0.7878, -0.3435, -1.3308,  0.4386, -0.1078,\n",
      "           -0.2736],\n",
      "          [ 1.4623,  0.5581,  0.7878, -0.3435, -1.3308,  0.4386, -0.1078,\n",
      "           -0.2736],\n",
      "          [ 1.7259, -0.4413, -0.1517,  0.2755, -0.8722, -0.7529, -1.5641,\n",
      "           -0.9575],\n",
      "          [ 1.7259, -0.4413, -0.1517,  0.2755, -0.8722, -0.7529, -1.5641,\n",
      "           -0.9575],\n",
      "          [-0.2509,  0.0434,  0.3033,  2.6338, -0.1515,  0.2691, -1.1761,\n",
      "            0.0842],\n",
      "          [-0.2509,  0.0434,  0.3033,  2.6338, -0.1515,  0.2691, -1.1761,\n",
      "            0.0842]],\n",
      "\n",
      "         [[ 0.4085, -0.1409,  1.7158,  0.8018, -0.4079,  0.7252, -0.2419,\n",
      "            0.7418],\n",
      "          [ 0.4085, -0.1409,  1.7158,  0.8018, -0.4079,  0.7252, -0.2419,\n",
      "            0.7418],\n",
      "          [ 1.1222, -1.3883,  1.2917, -0.4612, -1.9804, -1.1041, -0.1382,\n",
      "            0.1671],\n",
      "          [ 1.1222, -1.3883,  1.2917, -0.4612, -1.9804, -1.1041, -0.1382,\n",
      "            0.1671],\n",
      "          [ 0.6102,  1.5597, -2.1604,  1.6891,  0.7275,  0.6308, -0.4403,\n",
      "            0.7499],\n",
      "          [ 0.6102,  1.5597, -2.1604,  1.6891,  0.7275,  0.6308, -0.4403,\n",
      "            0.7499],\n",
      "          [ 0.8432,  1.8173, -1.1394,  1.1597,  0.3569, -2.2435,  0.6788,\n",
      "            0.8430],\n",
      "          [ 0.8432,  1.8173, -1.1394,  1.1597,  0.3569, -2.2435,  0.6788,\n",
      "            0.8430]],\n",
      "\n",
      "         [[-2.6243,  0.0688,  0.3284,  0.0297,  0.3668, -2.2625,  0.2016,\n",
      "            1.2607],\n",
      "          [-2.6243,  0.0688,  0.3284,  0.0297,  0.3668, -2.2625,  0.2016,\n",
      "            1.2607],\n",
      "          [ 0.0681,  0.6417,  0.2731,  0.1266, -0.4223,  0.4485, -0.7358,\n",
      "           -0.2751],\n",
      "          [ 0.0681,  0.6417,  0.2731,  0.1266, -0.4223,  0.4485, -0.7358,\n",
      "           -0.2751],\n",
      "          [-1.0429,  1.6223, -0.9959, -1.1272,  0.9117, -0.0953,  1.2329,\n",
      "            0.3859],\n",
      "          [-1.0429,  1.6223, -0.9959, -1.1272,  0.9117, -0.0953,  1.2329,\n",
      "            0.3859],\n",
      "          [ 0.7555,  0.9651, -0.3692, -2.5143,  0.3978, -1.1836, -1.2457,\n",
      "           -0.2673],\n",
      "          [ 0.7555,  0.9651, -0.3692, -2.5143,  0.3978, -1.1836, -1.2457,\n",
      "           -0.2673]]]])\n",
      "x shape: torch.Size([2, 3, 4, 8])\n",
      "x_repeated shape: torch.Size([2, 3, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "def repeat_kv_heads(x,rep_num):\n",
    "    \"\"\"\n",
    "    重复kv的头部\n",
    "    :param x: (bs, seqlen, n_heads, head_dim)\n",
    "    :param rep_num: 重复的次数\n",
    "    :return: (bs, seqlen, n_heads*rep_num, head_dim)\n",
    "    \"\"\"\n",
    "    if rep_num == 1:\n",
    "        return x\n",
    "    bs, seqlen, kv_head_num, head_dim = x.shape\n",
    "    return (\n",
    "        x[:,:,:,None,:].expand(bs,seqlen, kv_head_num, rep_num, head_dim).reshape(bs, seqlen, kv_head_num * rep_num, head_dim)\n",
    "    )\n",
    "\n",
    "#测试一下\n",
    "x= torch.randn(2, 3, 4, 8)  # (bs, seqlen, n_heads, head_dim)\n",
    "rep_num = 2  # 重复次数\n",
    "x_repeated = repeat_kv_heads(x, rep_num)\n",
    "print(\"x:\", x)  # 原始张量\n",
    "print(\"x_repeated:\", x_repeated)  # 重复后的张量\n",
    "print(\"x shape:\", x.shape)  # 应该是 (bs, seqlen, n_heads, head_dim)\n",
    "print(\"x_repeated shape:\", x_repeated.shape)  # 应该是 (bs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5449c2",
   "metadata": {},
   "source": [
    "# GQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "353b1ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask= tensor([[[[-1.0000e+09,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-1.0000e+09, -1.0000e+09,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "           -1.0000e+09,  0.0000e+00],\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "           -1.0000e+09, -1.0000e+09]]]])\n",
      "mask.shape= torch.Size([1, 1, 100, 100])\n",
      "freqs.shape= torch.Size([8])\n",
      "m.shape= torch.Size([100])\n",
      "freqs.shape= torch.Size([100, 8])\n",
      "pos_cis.shape= torch.Size([100, 8])\n",
      "xq_.shape= torch.Size([2, 100, 8, 8])\n",
      "pos_cis shape: torch.Size([1, 100, 1, 8])\n",
      "xq_ shape: torch.Size([2, 100, 8, 8])\n",
      "xk_ shape: torch.Size([2, 100, 8, 8])\n",
      "output_tensor.shape= torch.Size([2, 100, 128])\n",
      "past_kv: None\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import dropout, nn \n",
    "from torch.nn import functional as F\n",
    "import math\n",
    "class GroupQueryAttention(nn.Module):\n",
    "    def __init__(self,embed_dim,head_num,kv_head_num,dropout=0.1,Flash=False,training=True,max_seqlen=100):\n",
    "        super(GroupQueryAttention, self).__init__()\n",
    "        ### 基本参数\n",
    "        self.embed_dim=embed_dim\n",
    "        self.head_num=head_num\n",
    "        self.kv_head_num=kv_head_num\n",
    "        assert head_num % kv_head_num == 0, \"head_num must be divisible by kv_head_num\"\n",
    "        self.head_dim=embed_dim // head_num\n",
    "        assert self.head_dim* head_num == embed_dim, \"embed_dim must be divisible by head_num\"\n",
    "        self.rep_num = head_num // kv_head_num\n",
    "        self.dropout=dropout\n",
    "        self.scale = math.sqrt(self.head_dim)  # 缩放因子，通常是head_dim的平方根的倒数\n",
    "        self.max_seqlen=max_seqlen  # 最大序列长度\n",
    "\n",
    "        ### 网络结构\n",
    "        self.q_proj=nn.Linear(self.embed_dim,self.head_dim*self.head_num)\n",
    "        self.k_proj=nn.Linear(self.embed_dim,self.kv_head_num*self.head_dim)\n",
    "        self.v_proj=nn.Linear(self.embed_dim,self.kv_head_num*self.head_dim)\n",
    "        self.o_proj=nn.Linear(self.head_num*self.head_dim,self.embed_dim)\n",
    "        ### dropout等正则化层设置\n",
    "        self.attn_dropout=nn.Dropout(dropout)\n",
    "        self.res_dropout=nn.Dropout(dropout)\n",
    "        ### 其他参数\n",
    "        self.Flash = hasattr(F,'scaled_dot_product_attention') and Flash # 是否使用Flash Attention\n",
    "        self.training=training\n",
    "        ### 因果掩码初始化\n",
    "        ### 因果掩码作用的是q*k^T的结果,q=(bs,seqlen,head_num,head_dim),k=(bs,seqlen,kv_head_num*rep_num,head_dim)\n",
    "        ### q*k^T =(bs,seqlen,head_num,kv_head_num*rep_num)\n",
    "        mask=torch.full((1,1,self.max_seqlen,self.max_seqlen),float(\"-1e9\"))\n",
    "        mask=torch.tril(mask,diagonal=0)\n",
    "        print(\"mask=\",mask)\n",
    "        print(\"mask.shape=\",mask.shape)\n",
    "        self.register_buffer(\"mask\",mask)\n",
    "    \n",
    "    def forward(self,\n",
    "                x,\n",
    "                pos_cis=None,\n",
    "                past_key_value=None,\n",
    "                use_cache=False):\n",
    "        \"\"\"\n",
    "        :param x: (bs, seqlen, embed_dim)\n",
    "        :param pos_cis: (seqlen, head_dim//2) or None\n",
    "        :param past_key_value: (bs, seqlen, kv_head_num*rep_num, head_dim) or None\n",
    "        :param use_cache: 是否使用kv_cache\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        bs, seqlen, embed_dim = x.shape\n",
    "        ### qkv\n",
    "        xq=self.q_proj(x).reshape(bs,seqlen,self.head_num,self.head_dim)\n",
    "        xk=self.k_proj(x).reshape(bs,seqlen,self.kv_head_num,self.head_dim)\n",
    "        xv=self.v_proj(x).reshape(bs,seqlen,self.kv_head_num,self.head_dim)\n",
    "        xk= repeat_kv_heads(xk,self.rep_num)\n",
    "        xv= repeat_kv_heads(xv,self.rep_num)\n",
    "        ### 位置编码\n",
    "        if pos_cis is not None:\n",
    "            xq, xk = apply_rotary_emb(xq, xk, pos_cis)\n",
    "        else:\n",
    "            pos_cis= precompute_pos_cis(self.head_dim, seqlen, theta=1e5)\n",
    "            xq, xk = apply_rotary_emb(xq, xk, pos_cis)\n",
    "        ### kv_cache，仅推理模型可用\n",
    "        if past_key_value is not None:\n",
    "            xk = torch.cat([past_key_value[0], xk], dim=1)\n",
    "            xv = torch.cat([past_key_value[1], xv], dim=1)\n",
    "        past_kv= (xk, xv) if use_cache else None\n",
    "        xq,xk,xv=(\n",
    "            xq.transpose(1,2),\n",
    "            xk.transpose(1,2),\n",
    "            xv.transpose(1,2)\n",
    "        )\n",
    "        ### 计算注意力\n",
    "        dropout_p=self.dropout if self.training else 0.0\n",
    "        if self.Flash:\n",
    "            attn_out=F.scaled_dot_product_attention(\n",
    "                xq,xk,xv,\n",
    "                attn_mask=None, # 这里没有mask是因为is_causal=True时，Flash Attention会自动加上掩码计算\n",
    "                dropout_p=dropout_p,\n",
    "                is_causal=True\n",
    "            )\n",
    "        else:\n",
    "            attn_scores=torch.matmul(xq,xk.transpose(-2,-1)) / self.scale\n",
    "            attn_scores+=self.mask[:,:,:seqlen,:seqlen]\n",
    "            attn_weights=F.softmax(attn_scores,dim=-1)\n",
    "            attn_weights=self.attn_dropout(attn_weights)\n",
    "            attn_out=torch.matmul(attn_weights,xv)\n",
    "            attn_out=attn_out.transpose(1,2).reshape(bs,seqlen,self.head_num*self.head_dim)\n",
    "        ### 输出\n",
    "        attn_out=self.o_proj(attn_out)\n",
    "        attn_out=self.res_dropout(attn_out)\n",
    "        return attn_out, past_kv\n",
    "# 测试GroupQueryAttention\n",
    "embed_dim = 128  # 嵌入维度\n",
    "head_num = 8  # 注意力头数\n",
    "kv_head_num = 4  # kv头数\n",
    "dropout = 0.1  # dropout率\n",
    "max_seqlen=100\n",
    "group_query_attention = GroupQueryAttention(embed_dim, head_num, kv_head_num, dropout, max_seqlen=max_seqlen)\n",
    "# input_tensor是tokenizer输出的input_ids\n",
    "input_tensor = torch.randn(2, 100, embed_dim)  # 假设\n",
    "output_tensor, past_kv = group_query_attention(input_tensor)\n",
    "print(\"output_tensor.shape=\", output_tensor.shape)  # 输出张量的形状\n",
    "print(\"past_kv:\", past_kv)  # past_kv的内容\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f384e309",
   "metadata": {},
   "source": [
    "### FFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1ce8569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_tensor.shape= torch.Size([2, 100, 128])\n",
      "output_tensor tensor([[[-3.6558e-01, -5.2952e-02,  3.9966e-01,  ...,  3.5406e-01,\n",
      "           4.1486e-02, -7.8592e-01],\n",
      "         [ 1.3671e-01, -2.2398e-01, -1.4500e+00,  ..., -6.2017e-02,\n",
      "           2.2749e-01,  1.1504e+00],\n",
      "         [-1.3193e-01,  3.6840e-01,  2.3067e-01,  ...,  7.8578e-02,\n",
      "           1.7384e-01, -3.6819e-01],\n",
      "         ...,\n",
      "         [-2.5162e-01,  3.0838e-01, -9.8149e-02,  ..., -1.9799e-01,\n",
      "          -4.4678e-01,  5.3567e-01],\n",
      "         [-1.0654e-01, -7.2246e-02,  1.0375e-01,  ..., -7.3212e-02,\n",
      "           3.0868e-01,  6.0068e-01],\n",
      "         [ 2.8243e-01, -1.4833e-01, -2.1640e-01,  ...,  4.5890e-02,\n",
      "           6.4178e-02,  2.3454e-01]],\n",
      "\n",
      "        [[-2.7831e-02, -2.7405e-01, -5.7016e-02,  ..., -4.3016e-01,\n",
      "           2.2789e-01,  2.6693e-01],\n",
      "         [-2.3732e-01, -2.1335e-01,  3.4846e-04,  ..., -4.3830e-01,\n",
      "          -1.6731e-01,  3.3049e-01],\n",
      "         [ 7.7521e-01, -1.0378e-01,  7.2096e-01,  ...,  3.1679e-01,\n",
      "           2.0296e-01, -2.9089e-01],\n",
      "         ...,\n",
      "         [ 6.7792e-02, -4.4821e-02,  2.1556e-01,  ..., -3.0233e-01,\n",
      "           3.3679e-01,  1.7500e-02],\n",
      "         [ 1.4289e-01, -6.6923e-01,  1.3753e-01,  ..., -7.0470e-01,\n",
      "           1.4112e-01,  5.0317e-01],\n",
      "         [-2.3779e-01, -3.1787e-02, -7.0533e-02,  ...,  6.3238e-01,\n",
      "          -1.2832e-01, -9.2086e-02]]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self,embed_dim,ffn_dim,dropout=0.1):\n",
    "        super(FFN,self).__init__()\n",
    "        ### 自有参数\n",
    "        self.embed_dim=embed_dim\n",
    "        self.ffn_dim=ffn_dim\n",
    "        self.dropout=dropout\n",
    "        ### 网络结构\n",
    "        self.gate_proj=nn.Linear(embed_dim,ffn_dim)\n",
    "        self.up_proj=nn.Linear(embed_dim,ffn_dim)\n",
    "        self.down_proj=nn.Linear(ffn_dim,embed_dim)\n",
    "        ### dropout\n",
    "        self.gate_dropout=nn.Dropout(dropout)\n",
    "    def forward(self,x):\n",
    "        residual=F.silu(self.gate_proj(x))\n",
    "        residual=self.gate_dropout(residual)\n",
    "        x=self.up_proj(x)\n",
    "        x+= residual\n",
    "        x=self.down_proj(x)\n",
    "        return x\n",
    "# 测试FFN\n",
    "embed_dim = 128  # 嵌入维度\n",
    "ffn_dim = 512  # FFN维度\n",
    "dropout = 0.1  # dropout率\n",
    "ffn_layer = FFN(embed_dim, ffn_dim, dropout)\n",
    "# input_tensor是tokenizer输出的input_ids\n",
    "input_tensor = torch.randn(2, 100, embed_dim)  # 假设\n",
    "output_tensor = ffn_layer(input_tensor)\n",
    "print(\"output_tensor.shape=\", output_tensor.shape)  # 输出张量的形状\n",
    "print(\"output_tensor\", output_tensor)  # 输出张量的内容"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9fb95e",
   "metadata": {},
   "source": [
    "# 搭建block\n",
    "![img](../images/LLM-structure.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30e84c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask= tensor([[[[-1.0000e+09,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-1.0000e+09, -1.0000e+09,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "           -1.0000e+09,  0.0000e+00],\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "           -1.0000e+09, -1.0000e+09]]]])\n",
      "mask.shape= torch.Size([1, 1, 100, 100])\n",
      "freqs.shape= torch.Size([8])\n",
      "m.shape= torch.Size([100])\n",
      "freqs.shape= torch.Size([100, 8])\n",
      "pos_cis.shape= torch.Size([100, 8])\n",
      "xq_.shape= torch.Size([2, 100, 8, 8])\n",
      "pos_cis shape: torch.Size([1, 100, 1, 8])\n",
      "xq_ shape: torch.Size([2, 100, 8, 8])\n",
      "xk_ shape: torch.Size([2, 100, 8, 8])\n",
      "output_tensor.shape= torch.Size([2, 100, 128])\n",
      "past_kv: None\n"
     ]
    }
   ],
   "source": [
    "from turtle import pos\n",
    "import torch \n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "class MiniMindBlock(nn.Module):\n",
    "    def __init__(self,layer_id,seqlen,embed_dim,head_num,kv_head_num,ffn_dim):\n",
    "        super(MiniMindBlock,self).__init__()\n",
    "        ### 基本参数\n",
    "        self.layer_id=layer_id #记录layer编号\n",
    "        self.seqlen=seqlen # 序列长度\n",
    "        self.embed_dim=embed_dim\n",
    "        self.head_num=head_num\n",
    "        self.kv_head_num=kv_head_num\n",
    "        assert head_num % kv_head_num == 0, \"head_num must be divisible by kv_head_num\"\n",
    "        self.head_dim=embed_dim // head_num\n",
    "        assert self.head_dim* head_num == embed_dim, \"embed_dim must be divisible by head_num\"\n",
    "        self.rep_num = head_num // kv_head_num\n",
    "        self.ffn_dim=ffn_dim\n",
    "\n",
    "        ### 网络结构\n",
    "        self.norm1=RMSNorm(embed_dim)\n",
    "        self.attn=GroupQueryAttention(embed_dim,head_num,kv_head_num)\n",
    "        self.norm2=RMSNorm(embed_dim)\n",
    "        self.ffn=FFN(embed_dim,ffn_dim)\n",
    "        ### 额外的初始化\n",
    "        pos_cis=precompute_pos_cis(self.head_dim,self.seqlen)\n",
    "        self.register_buffer(\"pos_cis\",pos_cis)\n",
    "    def forward(self,x,\n",
    "                past_key_value=None,\n",
    "                use_cache=False):\n",
    "        \"\"\"\n",
    "        :param x: (bs, seqlen, embed_dim)\n",
    "        :param past_key_value: (bs, seqlen, kv_head_num*rep_num, head_dim) or None\n",
    "        :param use_cache: 是否使用kv_cache\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        ### 1. norm1\n",
    "        x=self.norm1(x)\n",
    "        ### 2. attn\n",
    "        attn_out, past_kv = self.attn(x,pos_cis=self.pos_cis,past_key_value=past_key_value,use_cache=use_cache)\n",
    "        ### 3. norm2\n",
    "        x=x+attn_out\n",
    "        x=self.norm2(x)\n",
    "        ### 4. ffn\n",
    "        x=x+self.ffn(x)\n",
    "        return x, past_kv\n",
    "# 测试MiniMindBlock\n",
    "layer_id = 0  # 层编号\n",
    "seqlen = 100  # 序列长度\n",
    "embed_dim = 128  # 嵌入维度\n",
    "head_num = 8  # 注意力头数\n",
    "kv_head_num = 4  # kv头数\n",
    "ffn_dim = 512  # FFN维度\n",
    "mini_mind_block = MiniMindBlock(layer_id, seqlen, embed_dim, head_num, kv_head_num, ffn_dim)\n",
    "# input_tensor是tokenizer输出的input_ids\n",
    "input_tensor = torch.randn(2, 100, embed_dim)  # 假设\n",
    "output_tensor, past_kv = mini_mind_block(input_tensor)\n",
    "print(\"output_tensor.shape=\", output_tensor.shape)  # 输出张量的形状\n",
    "print(\"past_kv:\", past_kv)  # past_kv的内容"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9642832b",
   "metadata": {},
   "source": [
    "# Minimind_Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c09c31e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask= tensor([[[[-1.0000e+09,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-1.0000e+09, -1.0000e+09,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "           -1.0000e+09,  0.0000e+00],\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "           -1.0000e+09, -1.0000e+09]]]])\n",
      "mask.shape= torch.Size([1, 1, 100, 100])\n",
      "freqs.shape= torch.Size([8])\n",
      "m.shape= torch.Size([100])\n",
      "freqs.shape= torch.Size([100, 8])\n",
      "pos_cis.shape= torch.Size([100, 8])\n",
      "mask= tensor([[[[-1.0000e+09,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-1.0000e+09, -1.0000e+09,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "           -1.0000e+09,  0.0000e+00],\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "           -1.0000e+09, -1.0000e+09]]]])\n",
      "mask.shape= torch.Size([1, 1, 100, 100])\n",
      "freqs.shape= torch.Size([8])\n",
      "m.shape= torch.Size([100])\n",
      "freqs.shape= torch.Size([100, 8])\n",
      "pos_cis.shape= torch.Size([100, 8])\n",
      "mask= tensor([[[[-1.0000e+09,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-1.0000e+09, -1.0000e+09,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "           -1.0000e+09,  0.0000e+00],\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "           -1.0000e+09, -1.0000e+09]]]])\n",
      "mask.shape= torch.Size([1, 1, 100, 100])\n",
      "freqs.shape= torch.Size([8])\n",
      "m.shape= torch.Size([100])\n",
      "freqs.shape= torch.Size([100, 8])\n",
      "pos_cis.shape= torch.Size([100, 8])\n",
      "mask= tensor([[[[-1.0000e+09,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-1.0000e+09, -1.0000e+09,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "           -1.0000e+09,  0.0000e+00],\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "           -1.0000e+09, -1.0000e+09]]]])\n",
      "mask.shape= torch.Size([1, 1, 100, 100])\n",
      "freqs.shape= torch.Size([8])\n",
      "m.shape= torch.Size([100])\n",
      "freqs.shape= torch.Size([100, 8])\n",
      "pos_cis.shape= torch.Size([100, 8])\n",
      "mask= tensor([[[[-1.0000e+09,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-1.0000e+09, -1.0000e+09,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "           -1.0000e+09,  0.0000e+00],\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "           -1.0000e+09, -1.0000e+09]]]])\n",
      "mask.shape= torch.Size([1, 1, 100, 100])\n",
      "freqs.shape= torch.Size([8])\n",
      "m.shape= torch.Size([100])\n",
      "freqs.shape= torch.Size([100, 8])\n",
      "pos_cis.shape= torch.Size([100, 8])\n",
      "mask= tensor([[[[-1.0000e+09,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-1.0000e+09, -1.0000e+09,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ...,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "            0.0000e+00,  0.0000e+00],\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "           -1.0000e+09,  0.0000e+00],\n",
      "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
      "           -1.0000e+09, -1.0000e+09]]]])\n",
      "mask.shape= torch.Size([1, 1, 100, 100])\n",
      "freqs.shape= torch.Size([8])\n",
      "m.shape= torch.Size([100])\n",
      "freqs.shape= torch.Size([100, 8])\n",
      "pos_cis.shape= torch.Size([100, 8])\n",
      "input_tensor= tensor([[1334, 2528, 1652, 4449, 2596, 5557, 5403, 6016, 2477, 6226,  288, 4293,\n",
      "         3699, 3216, 2767, 3407, 2776, 6170, 1658, 2801, 2928, 3772, 5581,  478,\n",
      "         4987, 3441, 5159, 3822, 5661, 2752, 6003,  954, 3841, 1358, 1803,  801,\n",
      "         5786,  741, 4821, 5388, 3508, 2170, 1139, 1094, 5579, 1546, 3675, 1370,\n",
      "         3283, 6099, 4842, 5114, 2378,  258, 3815, 1873, 2456, 6345, 4833, 5994,\n",
      "         6228, 4956, 1779, 4182, 3601, 3938, 5556,  201,  420, 4642, 6117, 2054,\n",
      "         6080, 5637, 1707, 5483, 2539, 5545, 5099, 6091,   58, 1260, 6018, 4279,\n",
      "         1077,  791, 2337, 1098, 4765, 2563,  126, 1964,  464, 6342, 1636, 2245,\n",
      "         6397, 3334, 1492, 5087],\n",
      "        [4623, 1618, 5420, 2413, 5465, 5366, 1665, 2305,  138, 5316, 4634, 3371,\n",
      "         3037,  175, 1751, 5592, 3425, 2370, 6338, 3695, 3305, 1660, 1794, 1568,\n",
      "         2970, 4148,  270, 2725,  875, 2932, 5056, 3158, 6306, 6140, 1377, 5695,\n",
      "         5320, 5489, 1837, 4766,  166, 4048, 1657, 1786, 4579, 2211, 2675, 2263,\n",
      "         4603, 2057, 5019, 4691, 5928, 5090, 1357, 5733, 5086, 4210,  298, 4758,\n",
      "         4372,  582, 5835, 4060, 2085, 3331, 5691, 1019, 3909, 5443, 1669, 4963,\n",
      "         4216, 1444, 4209, 1312, 1037, 5041,  814, 1861, 3077, 4779, 4568, 5897,\n",
      "         6294, 5251, 1098, 1504, 4885, 6258, 6251, 3473, 2126, 3916, 2621, 2311,\n",
      "          632, 2167, 1034,  831]])\n",
      "xq_.shape= torch.Size([2, 100, 8, 8])\n",
      "pos_cis shape: torch.Size([1, 100, 1, 8])\n",
      "xq_ shape: torch.Size([2, 100, 8, 8])\n",
      "xk_ shape: torch.Size([2, 100, 8, 8])\n",
      "xq_.shape= torch.Size([2, 100, 8, 8])\n",
      "pos_cis shape: torch.Size([1, 100, 1, 8])\n",
      "xq_ shape: torch.Size([2, 100, 8, 8])\n",
      "xk_ shape: torch.Size([2, 100, 8, 8])\n",
      "xq_.shape= torch.Size([2, 100, 8, 8])\n",
      "pos_cis shape: torch.Size([1, 100, 1, 8])\n",
      "xq_ shape: torch.Size([2, 100, 8, 8])\n",
      "xk_ shape: torch.Size([2, 100, 8, 8])\n",
      "xq_.shape= torch.Size([2, 100, 8, 8])\n",
      "pos_cis shape: torch.Size([1, 100, 1, 8])\n",
      "xq_ shape: torch.Size([2, 100, 8, 8])\n",
      "xk_ shape: torch.Size([2, 100, 8, 8])\n",
      "xq_.shape= torch.Size([2, 100, 8, 8])\n",
      "pos_cis shape: torch.Size([1, 100, 1, 8])\n",
      "xq_ shape: torch.Size([2, 100, 8, 8])\n",
      "xk_ shape: torch.Size([2, 100, 8, 8])\n",
      "xq_.shape= torch.Size([2, 100, 8, 8])\n",
      "pos_cis shape: torch.Size([1, 100, 1, 8])\n",
      "xq_ shape: torch.Size([2, 100, 8, 8])\n",
      "xk_ shape: torch.Size([2, 100, 8, 8])\n",
      "output_tensor= tensor([[[6.7190e-05, 1.6816e-04, 9.3765e-05,  ..., 8.1391e-05,\n",
      "          1.7268e-04, 8.5727e-05],\n",
      "         [1.7185e-04, 2.5484e-04, 1.3034e-04,  ..., 1.3503e-04,\n",
      "          1.5335e-04, 9.8896e-05],\n",
      "         [2.1424e-04, 1.2382e-04, 1.3051e-04,  ..., 3.3699e-05,\n",
      "          2.1288e-04, 1.3184e-04],\n",
      "         ...,\n",
      "         [6.4101e-05, 1.7326e-04, 2.0781e-04,  ..., 1.9345e-04,\n",
      "          6.8446e-05, 1.2156e-04],\n",
      "         [4.4192e-05, 4.4332e-04, 7.6341e-05,  ..., 5.1840e-05,\n",
      "          4.7366e-05, 2.8291e-04],\n",
      "         [9.4590e-05, 1.3215e-04, 3.4423e-04,  ..., 1.1813e-04,\n",
      "          4.1408e-05, 5.5530e-05]],\n",
      "\n",
      "        [[1.5885e-04, 7.4741e-05, 8.5101e-05,  ..., 4.3228e-04,\n",
      "          2.7616e-04, 2.6812e-04],\n",
      "         [2.7041e-04, 6.9202e-05, 1.9897e-04,  ..., 2.3246e-04,\n",
      "          4.9795e-05, 6.3514e-05],\n",
      "         [2.1702e-04, 1.3884e-04, 1.0270e-04,  ..., 5.2728e-04,\n",
      "          1.2941e-04, 1.8209e-04],\n",
      "         ...,\n",
      "         [1.8910e-04, 5.8684e-05, 2.3733e-04,  ..., 4.2889e-05,\n",
      "          8.0703e-05, 4.0278e-05],\n",
      "         [1.1544e-04, 6.6428e-05, 1.2322e-04,  ..., 9.4942e-05,\n",
      "          2.7545e-04, 1.0147e-04],\n",
      "         [1.1918e-04, 5.0689e-05, 1.8287e-04,  ..., 5.5810e-05,\n",
      "          1.1201e-04, 2.4020e-04]]], grad_fn=<SoftmaxBackward0>)\n",
      "output_tensor.shape= torch.Size([2, 100, 6400])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "class MiniMindLM(nn.Module):\n",
    "    def __init__(self,vocab_size,embed_dim,head_num,kv_head_num,ffn_dim,num_layers,max_seqlen=100):\n",
    "        super(MiniMindLM,self).__init__()\n",
    "        ### 基本参数\n",
    "        self.vocab_size=vocab_size\n",
    "        self.embed_dim=embed_dim\n",
    "        self.head_num=head_num\n",
    "        self.kv_head_num=kv_head_num\n",
    "        assert head_num % kv_head_num == 0, \"head_num must be divisible by kv_head_num\"\n",
    "        self.head_dim=embed_dim // head_num\n",
    "        assert self.head_dim* head_num == embed_dim, \"embed_dim must be divisible by head_num\"\n",
    "        self.rep_num = head_num // kv_head_num\n",
    "        self.ffn_dim=ffn_dim\n",
    "        self.num_layers=num_layers\n",
    "        self.max_seqlen=max_seqlen\n",
    "\n",
    "        ### 网络结构\n",
    "        self.embedding=Embedding(vocab_size,embed_dim)\n",
    "        self.blocks=nn.ModuleList([\n",
    "            MiniMindBlock(i,self.max_seqlen,embed_dim,head_num,kv_head_num,ffn_dim)\n",
    "            for i in range(num_layers)\n",
    "        ])\n",
    "        self.norm=RMSNorm(embed_dim)\n",
    "        self.lm_head=nn.Linear(embed_dim,vocab_size)\n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "        :param x: (bs, seqlen)\n",
    "        :return: (bs, seqlen, vocab_size)\n",
    "        \"\"\"\n",
    "        bs, seqlen = x.shape\n",
    "        ### 1. embedding\n",
    "        x=self.embedding(x)\n",
    "        ### 2. blocks\n",
    "        past_kv=None\n",
    "        for i,block in enumerate(self.blocks):\n",
    "            x,past_kv=block(x,past_key_value=past_kv,use_cache=False)\n",
    "        ### 3. norm\n",
    "        x=self.norm(x)\n",
    "        ### 4. lm_head\n",
    "        logits=self.lm_head(x)\n",
    "        logits=F.softmax(logits, dim=-1)  # 对最后一维进行softmax\n",
    "        return logits\n",
    "# 测试MiniMindLM\n",
    "vocab_size = tokenizer.vocab_size\n",
    "embed_dim = 128  # 嵌入维度\n",
    "head_num = 8  # 注意力头数\n",
    "kv_head_num = 4  # kv头数\n",
    "ffn_dim = 512  # FFN维度\n",
    "num_layers = 6  # 层数\n",
    "max_seqlen = 100  # 最大序列长度\n",
    "mini_mind_lm = MiniMindLM(vocab_size, embed_dim, head_num,\n",
    "                            kv_head_num, ffn_dim, num_layers, max_seqlen=max_seqlen)\n",
    "# input_tensor是tokenizer输出的input_ids\n",
    "input_tensor = torch.randint(0, vocab_size, (2, 100))  #\n",
    "print(\"input_tensor=\", input_tensor)  # 假设输入的tensor形状为[batch_size, seq_length]\n",
    "# 假设输入的tensor形状为[batch_size, seq_length]\n",
    "output_tensor = mini_mind_lm(input_tensor)\n",
    "print(\"output_tensor=\", output_tensor)  # 输出张量的内容\n",
    "print(\"output_tensor.shape=\", output_tensor.shape)  # 输出张量的形状\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f92ccb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minimind",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
