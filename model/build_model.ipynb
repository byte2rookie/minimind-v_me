{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "246ad362",
   "metadata": {},
   "source": [
    "# 搭建Minimind模型\n",
    "首先要理清模型结构<br>\n",
    "![structure](../images/LLM-structure.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1d3b34",
   "metadata": {},
   "source": [
    "# 搭建思路\n",
    "采用自底向上的方式搭建model，理清所有的因素\n",
    "- tokenizer\n",
    "- embedding\n",
    "- AttentionBlock\n",
    "- ffn\n",
    "- output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540ea420",
   "metadata": {},
   "source": [
    "# tokenizer\n",
    "在此之前已经训练好了tokenizer了，这里我们就开始利用之前训练好的tokenizer，来将原始信息转为input_ids的结构<br>\n",
    "这里学习到的点：padding来统一输出input_ids的形状。left-padding和right-padding也是常见考察点<br>\n",
    "注意！tokenizer初始化的时候就定好了padding的方向了，后续无法更改的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46da48af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs_r.shape= torch.Size([2, 100])\n",
      "inputs_r tensor([[   1,   87,   93,  307,   73,   81,  203,  397,  924, 5235, 3317, 2117,\n",
      "          265, 2603, 1132, 2599,  703,  472,  997,    2,  203,    1,   89,   87,\n",
      "         3709,  203,  397, 2722, 3016,  425,    2,  203,    1,   69,   87,   87,\n",
      "           77,  307, 3924,   88,  203,  301, 2722, 1284,    2,  203,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   1,   87,   93,  307,   73,   81,  203,  397,  924, 5990, 2391,  328,\n",
      "          240,  101, 3789, 2117,  265, 2603, 1132, 1395,  264,  703,  472,  997,\n",
      "            2,  203,    1,   89,   87, 3709,  203,  397, 2722, 3016,  425,    2,\n",
      "          203,    1,   69,   87,   87,   77,  307, 3924,   88,  203,  301, 2722,\n",
      "         4863,    2,  203,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0]])\n",
      "inputs_l.shape= torch.Size([2, 100])\n",
      "inputs_l tensor([[   1,   87,   93,  307,   73,   81,  203,  397,  924, 5235, 3317, 2117,\n",
      "          265, 2603, 1132, 2599,  703,  472,  997,    2,  203,    1,   89,   87,\n",
      "         3709,  203,  397, 2722, 3016,  425,    2,  203,    1,   69,   87,   87,\n",
      "           77,  307, 3924,   88,  203,  301, 2722, 1284,    2,  203,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   1,   87,   93,  307,   73,   81,  203,  397,  924, 5990, 2391,  328,\n",
      "          240,  101, 3789, 2117,  265, 2603, 1132, 1395,  264,  703,  472,  997,\n",
      "            2,  203,    1,   89,   87, 3709,  203,  397, 2722, 3016,  425,    2,\n",
      "          203,    1,   69,   87,   87,   77,  307, 3924,   88,  203,  301, 2722,\n",
      "         4863,    2,  203,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0]])\n",
      "torch.Size([2, 100])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "from numpy import pad\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer_path=\"./\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path,padding_side=\"right\") # padding_side可以是\"left\"或\"right\"，默认是\"right\"\n",
    "#单条信息的情况,batch=1\n",
    "messages = [[\n",
    "        {\"role\": \"system\", \"content\": \"你是一个优秀的聊天机器人，总是给我正确的回应！\"},\n",
    "        {\"role\": \"user\", \"content\": '你来自哪里？'},\n",
    "        {\"role\": \"assistant\", \"content\": '我来自地球'}\n",
    "    ],[\n",
    "        {\"role\": \"system\", \"content\": \"你是一个糟糕的捣乱机器人，总是给我错误的回应！\"},\n",
    "        {\"role\": \"user\", \"content\": '你来自哪里？'},\n",
    "        {\"role\": \"assistant\", \"content\": '我来自火星'}\n",
    "    ],\n",
    "    ]\n",
    "#多条信息\n",
    "\n",
    "inputs_r = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True,return_tensors=\"pt\",padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=100,\n",
    "    padding_side=\"right\"# 可以尝试\"left\"或\"right\"\n",
    "    ) #直接使用会导致长度不一致的典型问题，因此需要padding到一致长度\n",
    "print(\"inputs_r.shape=\",inputs_r.shape)\n",
    "print(\"inputs_r\",inputs_r)\n",
    "inputs_l = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True,return_tensors=\"pt\",padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=100,\n",
    "    padding_side=\"left\"# 可以尝试\"left\"或\"right\"\n",
    "    )\n",
    "print(\"inputs_l.shape=\",inputs_l.shape)\n",
    "print(\"inputs_l\",inputs_l)\n",
    "\n",
    "#由于一开始tokenizer初始化的时候就定好了padding的方向了，所以后续无法更改的。上面也对比出来了\n",
    "\n",
    "input_ids=inputs_r\n",
    "print(input_ids.shape)\n",
    "print(type(input_ids))\n",
    "# 可知有很多tokenizer输出的tensor形状了\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8429e4c6",
   "metadata": {},
   "source": [
    "# embedding\n",
    "tokenizer实现了word2vec，而下一步就是将原始的类似one-hot编码转化为向量化的压缩的input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee0d5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res.shape= torch.Size([2, 100, 128])\n",
      "res tensor([[[-0.3168,  0.9605, -0.6649,  ..., -0.4188, -0.7787, -0.3694],\n",
      "         [ 0.2875,  0.8859,  0.8194,  ...,  1.5720,  0.2437, -1.4731],\n",
      "         [ 2.0624,  2.5026, -0.3948,  ..., -0.8403,  0.6490,  1.8705],\n",
      "         ...,\n",
      "         [-0.1398, -1.4757,  2.4973,  ...,  0.9886,  1.8192,  0.4483],\n",
      "         [-0.1398, -1.4757,  2.4973,  ...,  0.9886,  1.8192,  0.4483],\n",
      "         [-0.1398, -1.4757,  2.4973,  ...,  0.9886,  1.8192,  0.4483]],\n",
      "\n",
      "        [[-0.3168,  0.9605, -0.6649,  ..., -0.4188, -0.7787, -0.3694],\n",
      "         [ 0.2875,  0.8859,  0.8194,  ...,  1.5720,  0.2437, -1.4731],\n",
      "         [ 2.0624,  2.5026, -0.3948,  ..., -0.8403,  0.6490,  1.8705],\n",
      "         ...,\n",
      "         [-0.1398, -1.4757,  2.4973,  ...,  0.9886,  1.8192,  0.4483],\n",
      "         [-0.1398, -1.4757,  2.4973,  ...,  0.9886,  1.8192,  0.4483],\n",
      "         [-0.1398, -1.4757,  2.4973,  ...,  0.9886,  1.8192,  0.4483]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#实现embedding\n",
    "import torch\n",
    "from torch import nn\n",
    "# embedding\n",
    "class Embedding(nn.Module):\n",
    "    def __init__(self,vocab_size,embed_dim):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "    def forward(self,input_ids):\n",
    "        return self.embedding(input_ids)\n",
    "\n",
    "# 测试embedding\n",
    "vocab_size = tokenizer.vocab_size\n",
    "embed_dim = 128  # 嵌入维度\n",
    "embedding_layer = Embedding(vocab_size, embed_dim)\n",
    "# input_ids是tokenizer输出的input_ids\n",
    "res= embedding_layer(input_ids)\n",
    "print(\"res.shape=\",res.shape)\n",
    "print(\"res\",res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c173daa5",
   "metadata": {},
   "source": [
    "# AttentionBlock\n",
    "主要分为三个组件\n",
    "- RMSNorm\n",
    "- GQA\n",
    "- FFN\n",
    "embedding结束后，输入向量压缩为了[2,100,128]的tensor<br>\n",
    "将这个tensor输入attentionblock，捕捉tensor内部的注意力关系<br>\n",
    "这里采用的GQA机制，需要实现GQA，还需要实现RoPE编码，从而捕捉tensor内部的位置和时序关系\n",
    "![img](../images/LLM-structure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5ffedc",
   "metadata": {},
   "source": [
    "## RMSNorm\n",
    "### 均方根层归一化 (Root Mean Square Layer Normalization, RMSNorm)\n",
    "\n",
    "RMSNorm 是对 LayerNorm 的一个改进,  没有做 re-center 操作（移除了均值项）, 可以看作 LayerNorm 在均值为零时的特例, 使用平方根均值归一化降低噪声影响。\n",
    "\n",
    "- **Layer Norm**\n",
    "\n",
    "$$y = \\frac{x-E(x)}{\\sqrt{Var(x) + \\epsilon}} * \\gamma + \\beta$$\n",
    "\n",
    "假设输入张量形状为 (batch_size,  sequence_length,  embedding_dim), 层归一化对 embedding_dim 维度进行归一化操作, 其中,  $\\epsilon$ 是一个超参数, 用于防止分母为零导致结果上溢,  $\\gamma$,  $\\beta$ 均为可学习参数。\n",
    "\n",
    "- **RMS Norm**\n",
    "\n",
    "$$a_i=\\frac{a_i}{RMS(a) + \\epsilon} * \\gamma,  \\quad where \\quad RMS(a) = \\sqrt{\\frac{1}{n}\\sum^n_{i=1}a^2_i}.$$\n",
    "\n",
    "假设输入张量形状为 (batch_size,  sequence_length,  embedding_dim), RMS Norm 对 embedding_dim 维度进行归一化,其中,  其中,  $\\epsilon$ 是一个超参数, 用于防止分母为零导致结果上溢, $\\gamma$ 为可学习参数.\n",
    "\n",
    "不难发现, 当均值为零时, Layer Norm 退化为 RMS Norm. 这是因为 RMS Norm 在 Layer Norm 的基础上舍弃了中心化操作, 仅用缩放进行归一化, 其不改变数据原本的分布, 有利于激活函数输出的稳定."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99585b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_tensor tensor([[[-0.0319, -0.8763, -0.0228,  ...,  0.2425,  1.8407,  1.4291],\n",
      "         [-0.9328,  0.3192, -0.7244,  ..., -0.1701,  0.1923, -0.9579],\n",
      "         [-0.8071,  0.0079, -0.8318,  ...,  0.2133, -1.6108, -0.6445],\n",
      "         ...,\n",
      "         [-0.2219,  2.1274,  0.8018,  ..., -0.2066,  0.1366, -0.2633],\n",
      "         [ 0.0508, -0.4104, -1.8380,  ...,  0.2081,  0.4585, -0.5310],\n",
      "         [-0.2338,  1.0565, -0.0239,  ..., -0.3222,  1.2725,  0.9124]],\n",
      "\n",
      "        [[ 0.5747, -0.2042, -0.8613,  ..., -0.4730, -1.0729,  0.4904],\n",
      "         [ 1.9128,  0.8612,  1.1180,  ...,  0.6216,  0.4002,  0.2998],\n",
      "         [-2.3053, -0.4935, -0.4944,  ..., -1.4535,  0.8217,  0.1968],\n",
      "         ...,\n",
      "         [-0.7073, -1.4368,  0.3273,  ..., -0.4203,  0.8883, -0.1376],\n",
      "         [-0.1859,  1.2741, -0.1814,  ..., -0.3975, -0.6768, -0.5402],\n",
      "         [ 1.8041, -0.5722, -1.4134,  ...,  1.3582, -0.2085, -1.2377]]])\n",
      "output_tensor tensor([[[-0.0305, -0.8394, -0.0218,  ...,  0.2323,  1.7632,  1.3689],\n",
      "         [-0.9186,  0.3144, -0.7134,  ..., -0.1675,  0.1894, -0.9433],\n",
      "         [-0.8245,  0.0081, -0.8498,  ...,  0.2179, -1.6456, -0.6584],\n",
      "         ...,\n",
      "         [-0.2314,  2.2183,  0.8361,  ..., -0.2154,  0.1424, -0.2745],\n",
      "         [ 0.0564, -0.4557, -2.0407,  ...,  0.2311,  0.5090, -0.5895],\n",
      "         [-0.2293,  1.0359, -0.0235,  ..., -0.3159,  1.2477,  0.8946]],\n",
      "\n",
      "        [[ 0.5610, -0.1994, -0.8408,  ..., -0.4617, -1.0474,  0.4788],\n",
      "         [ 2.0824,  0.9376,  1.2171,  ...,  0.6767,  0.4357,  0.3264],\n",
      "         [-2.3284, -0.4984, -0.4993,  ..., -1.4681,  0.8299,  0.1988],\n",
      "         ...,\n",
      "         [-0.7375, -1.4982,  0.3413,  ..., -0.4383,  0.9262, -0.1435],\n",
      "         [-0.2366,  1.6213, -0.2309,  ..., -0.5058, -0.8613, -0.6874],\n",
      "         [ 1.8435, -0.5847, -1.4443,  ...,  1.3879, -0.2130, -1.2647]]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self,embed_dim,eps=1e-6):\n",
    "        super(RMSNorm,self).__init__()\n",
    "        self.embed_dim=embed_dim\n",
    "        self.eps=eps\n",
    "        self.weight=nn.Parameter(torch.ones(embed_dim))\n",
    "    def forward(self,x):\n",
    "        return x*torch.rsqrt(x.pow(2).mean(-1,keepdim=True)+self.eps).type_as(x)*self.weight\n",
    "# 测试RMSNorm\n",
    "embed_dim = 128  # 嵌入维度\n",
    "rmsnorm_layer = RMSNorm(embed_dim)\n",
    "input_tensor = torch.randn(2, 100, embed_dim)  # 假设输入的tensor形状为[batch_size, seq_length, embed_dim]\n",
    "output_tensor = rmsnorm_layer(input_tensor)\n",
    "print(\"input_tensor\",input_tensor)\n",
    "print(\"output_tensor\",output_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bf6984",
   "metadata": {},
   "source": [
    "## RoPE\n",
    "### Rotary Position Embedding, RoPE\n",
    "\n",
    "旋转位置编码是一种能将相对位置信息集成到 self-attention 中, 进而提升 transformer 架构性能的位置编码方式, 和绝对位置编码相比, RoPE 具有很好的外推性, 是目前的主流位置编码方式.\n",
    "\n",
    "外推性的解释, 通俗来说就是训练的时候限制了 512 的上下文长度，那么推理时如果面对超过该长度的文本，LLM 可能无法正确处理.\n",
    "\n",
    "- **绝对位置编码**\n",
    "\n",
    "绝对位置编码是早期 Transformer 架构采用的绝对位置编码方案，及那个每个位置映射为固定的向量表示.\n",
    "\n",
    "$$f_{t:t\\in\\{q,k,v\\}}(\\boldsymbol{x}_i,i)=\\boldsymbol{W}_{t:t\\in\\{q,k,v\\}}(\\boldsymbol{x}_i+\\boldsymbol{p}_i)$$\n",
    "\n",
    "其中编码向量 $p_i$ 的计算使用如下公式：\n",
    "\n",
    "$$\\boldsymbol{p}_{i,2t}=\\sin\\left(k/1000^{2t/d}\\right), \\boldsymbol{p}_{i,2t+1}=\\cos\\left(k/1000^{2t/d}\\right)$$\n",
    "\n",
    "正如其名，绝对位置编码只考虑了输入序列中的绝对位置关系，对于 token 之间的相对信息则没有纳入考虑.\n",
    "\n",
    "- **旋转位置编码**\n",
    "\n",
    "假定 query 和 key 的内积操作可以被函数 g 表示，该函数 g 的输入是词嵌入向量 $x_m, x_n$ 和它们之间的相对位置 $m-n$:\n",
    "\n",
    "$$<f_q(x_m ,m), f_k(x_n, n)>=g(x_m, x_n, m, n)$$\n",
    "\n",
    "旋转位置编码就是找到一个使上式成立的位置编码方式. \n",
    "\n",
    "出于认识的目的，我们省略复杂的数学推导，直接看 RoPE 的的结论：\n",
    "\n",
    "存在这样一个正交矩阵：\n",
    "\n",
    "$$\\boldsymbol{R}_{\\Theta,m}^d=\\underbrace{\\begin{pmatrix}\\cos m\\theta_0&-\\sin m\\theta_0&0&0&\\cdots&0&0\\\\\\sin m\\theta_0&\\cos m\\theta_0&0&0&\\cdots&0&0\\\\0&0&\\cos m\\theta_1&-\\sin m\\theta_1&\\cdots&0&0\\\\0&0&\\sin m\\theta_1&\\cos m\\theta_1&\\cdots&0&0\\\\\\vdots&\\vdots&\\vdots&\\vdots&\\ddots&\\vdots&\\vdots\\\\0&0&0&0&\\cdots&\\cos m\\theta_{d/2-1}&-\\sin m\\theta_{d/2-1}&-\\sin m\\theta_{d/2-1}\\end{pmatrix}}_{\\boldsymbol{W}_m}$$\n",
    "\n",
    "其中，$\\Theta=\\left\\{\\theta_i=10000^{-2(i-1)/d},i\\in[1,2,\\ldots,d/2]\\right\\}$\n",
    "\n",
    "我们可以将 query 和 key 的内积操作转换为与原始向量 $x$ 相关的以下等价形式：\n",
    "\n",
    "$$\n",
    "\\boldsymbol{q}_m^\\mathbf{T}\\boldsymbol{k}_n=\\left(\\boldsymbol{R}_{\\Theta,m}^d\\boldsymbol{W}_q\\boldsymbol{x}_m\\right)^\\mathbf{T}\\left(\\boldsymbol{R}_{\\Theta,n}^d\\boldsymbol{W}_k\\boldsymbol{x}_n\\right)=\\boldsymbol{x}_m^\\mathbf{T}\\boldsymbol{W}_q\\boldsymbol{R}_{\\Theta,n-m}^d\\boldsymbol{W}_k\\boldsymbol{x}_n\n",
    "$$\n",
    "\n",
    "其中， $\\boldsymbol{R}_{\\Theta,n-m}^d=\\left(\\boldsymbol{R}_{\\Theta,m}^d\\right)^\\mathbf{T}\\boldsymbol{R}_{\\Theta,n}^d$.\n",
    "\n",
    "由于 $\\boldsymbol{R}_{\\Theta,m}^d$ 的稀疏性，直接使用矩阵乘法会浪费算力，因此代码中采用下述方式实现：\n",
    "\n",
    "$$\\boldsymbol{R}_{\\Theta,m}^{d}\\boldsymbol{x}=\\begin{pmatrix}x_{0}\\\\x_{1}\\\\x_{2}\\\\x_{3}\\\\\\vdots\\\\x_{d-2}\\\\x_{d-1}\\end{pmatrix}\\otimes\\begin{pmatrix}\\cos m\\theta_{0}\\\\\\cos m\\theta_{0}\\\\\\cos m\\theta_{1}\\\\\\cos m\\theta_{1}\\\\\\vdots\\\\\\cos m\\theta_{d/2-1}\\\\\\cos m\\theta_{d/2-1}\\end{pmatrix}+\\begin{pmatrix}-x_{1}\\\\x_{0}\\\\-x_{3}\\\\x_{2}\\\\\\vdots\\\\-x_{d-1}\\\\x_{d-2}\\end{pmatrix}\\otimes\\begin{pmatrix}\\sin m\\theta_{0}\\\\\\sin m\\theta_{0}\\\\\\sin m\\theta_{1}\\\\\\sin m\\theta_{1}\\\\\\vdots\\\\\\sin m\\theta_{d/2-1}\\\\\\sin m\\theta_{d/2-1}\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c1a7fc",
   "metadata": {},
   "source": [
    "简而言之，RoPE就是用绝对编码的形式，表示出相对编码的关系，这样同时具有了绝对编码的简洁和相对编码的位置信息泛化性<br>\n",
    "此处的ROPE的实现主要参考的是LLama的RoPE实现\n",
    "[LLAMA实现](https://blog.csdn.net/m0_55846238/article/details/145728695)<br>\n",
    "对旋转编码理解困难，可以参考[无痛理解RoPE](https://zhuanlan.zhihu.com/p/8306958113)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157c23d2",
   "metadata": {},
   "source": [
    "大概归纳一下，旋转编码主要两步，首先是制作 $m\\Theta$ 的旋转角度的表，之后再应用这个表，用于编码qk\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bfc96f",
   "metadata": {},
   "source": [
    "### 首先制作$m\\Theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a81b9293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freqs.shape= torch.Size([64])\n",
      "m.shape= torch.Size([100])\n",
      "freqs.shape= torch.Size([100, 64])\n",
      "pos_cis.shape= torch.Size([100, 64])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "def precompute_pos_cis(dim,seqlen,theta=1e5):\n",
    "    #这里//2是因为要把dim分成两半，前半部分用于cos，后半部分用于sin，所以只会用到一个theta\n",
    "    freqs=1.0/(theta**(torch.arange(0,dim,2)[:dim//2].float()/dim))\n",
    "    print(\"freqs.shape=\",freqs.shape)\n",
    "    \n",
    "    m=torch.arange(seqlen,device=freqs.device)\n",
    "    print(\"m.shape=\",m.shape)\n",
    "\n",
    "    freqs=torch.outer(m,freqs).float()\n",
    "    print(\"freqs.shape=\",freqs.shape)\n",
    "\n",
    "    pos_cis=torch.polar(torch.ones_like(freqs),freqs)\n",
    "    print(\"pos_cis.shape=\",pos_cis.shape)\n",
    "    return pos_cis\n",
    "\n",
    "# 测试precompute_pos_cis\n",
    "dim = 128  # 嵌入维度\n",
    "seqlen = 100  # 序列长度\n",
    "pos_cis = precompute_pos_cis(dim, seqlen)\n",
    "print(type(pos_cis))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dc3bd1",
   "metadata": {},
   "source": [
    "### 然后将$m\\Theta$应用到旋转编码计算中去"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a6d928d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freqs.shape= torch.Size([4])\n",
      "m.shape= torch.Size([3])\n",
      "freqs.shape= torch.Size([3, 4])\n",
      "pos_cis.shape= torch.Size([3, 4])\n",
      "<class 'torch.Tensor'>\n",
      "xq_.shape= torch.Size([2, 3, 2, 4])\n",
      "pos_cis shape: torch.Size([1, 3, 1, 4])\n",
      "xq_ shape: torch.Size([2, 3, 2, 4])\n",
      "xk_ shape: torch.Size([2, 3, 2, 4])\n",
      "xq shape: torch.Size([2, 3, 2, 8])\n",
      "xk shape: torch.Size([2, 3, 2, 8])\n",
      "xq_out_shape: torch.Size([2, 3, 2, 8])\n",
      "xk_out_shape: torch.Size([2, 3, 2, 8])\n",
      "pos_cis: tensor([[ 1.0000+0.0000e+00j,  1.0000+0.0000e+00j,  1.0000+0.0000e+00j,\n",
      "          1.0000+0.0000e+00j],\n",
      "        [ 0.5403+8.4147e-01j,  0.9984+5.6204e-02j,  1.0000+3.1623e-03j,\n",
      "          1.0000+1.7783e-04j],\n",
      "        [-0.4161+9.0930e-01j,  0.9937+1.1223e-01j,  1.0000+6.3245e-03j,\n",
      "          1.0000+3.5566e-04j]])\n",
      "pos_cis shape: torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "def apply_rotary_emb(xq,xk,pos_cis):\n",
    "    xq_=torch.view_as_complex(xq.float().reshape(*xq.shape[:-1],-1,2))\n",
    "    xk_=torch.view_as_complex(xk.float().reshape(*xk.shape[:-1],-1,2))\n",
    "    #由于view_as_complex,最后一维合并了，就变成了dim//2的形状\n",
    "    print(\"xq_.shape=\",xq_.shape)\n",
    "    def unite_shape(pos_cis,x):\n",
    "        #将pos_cis对齐x的形状\n",
    "        ndim = x.ndim\n",
    "        assert 0 <= 1 < ndim\n",
    "        #x形状一般为(batch_size, seq_len, n_heads, head_dim//2)\n",
    "        #这里确保freqs_cis与x的seq_len, head_dim//2维度一致, RoPE是对每个头分别进行的\n",
    "        assert pos_cis.shape == (x.shape[1],  x.shape[-1]),f\"pos_cis.shape:({pos_cis.shape}),(x.shape[1],  x.shape[-1])={(x.shape[1],  x.shape[-1])}\"\n",
    "        shape = [d if i == 1 or i == ndim - 1 else 1 for i,  d in enumerate(x.shape)]\n",
    "        return pos_cis.view(*shape)\n",
    "    pos_cis = unite_shape(pos_cis, xq_)\n",
    "    #将pos_cis应用到xq_和xk_上(和输入对齐)\n",
    "    print(\"pos_cis shape:\", pos_cis.shape)\n",
    "    print(\"xq_ shape:\", xq_.shape)\n",
    "    print(\"xk_ shape:\", xk_.shape)\n",
    "    xq_out=torch.view_as_real(xq_ * pos_cis).flatten(3)\n",
    "    xk_out=torch.view_as_real(xk_ * pos_cis).flatten(3)\n",
    "    return xq_out, xk_out\n",
    "#测试一下apply_rotary_emb函数\n",
    "xq = torch.randn(2, 3, 2,8)  # (bs, seqlen, dim)\n",
    "xk = torch.randn(2, 3, 2,8)  # (bs, seqlen, dim)\n",
    "pos_cis = precompute_pos_cis(dim=8, seqlen=3, theta=1e5)\n",
    "print(type(pos_cis))\n",
    "xq_out, xk_out = apply_rotary_emb(xq, xk, pos_cis)\n",
    "print(\"xq shape:\", xq.shape)  # 应该是 (bs, seqlen, dim)\n",
    "print(\"xk shape:\", xk.shape)  # 应该是 (bs, seqlen, dim)\n",
    "\n",
    "print(\"xq_out_shape:\", xq_out.shape)  # 应该是 (bs, seqlen, dim\n",
    "print(\"xk_out_shape:\", xk_out.shape)  # 应该是 (bs, seqlen, dim\n",
    "# print(\"xq_out:\", xq_out)\n",
    "# print(\"xk_out:\", xk_out)\n",
    "print(\"pos_cis:\", pos_cis)\n",
    "print(\"pos_cis shape:\", pos_cis.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0284e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minimind",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
